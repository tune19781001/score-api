from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.memory import VectorStoreRetrieverMemory
import os

# æ°¸ç¶šä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€ã‚’æŒ‡å®šï¼ˆRenderå¯¾å¿œï¼‰
persist_dir = "./memory_store"
os.makedirs(persist_dir, exist_ok=True)

# ãƒ™ã‚¯ãƒˆãƒ«è¨˜æ†¶ã®åˆæœŸåŒ–ï¼ˆä»Šåº¦ã¯ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚ã‚Šï¼ï¼‰
embedding = OpenAIEmbeddings()
vectorstore = Chroma(
    embedding_function=embedding,
    persist_directory=persist_dir
)

# LangChainç”¨ã®è¨˜æ†¶ãƒ¡ãƒ¢ãƒªã‚’ä½œæˆ
memory = VectorStoreRetrieverMemory(retriever=vectorstore.as_retriever())

def save_judgment(input_text: str, result: str):
    """æ’å·ã•ã‚“ã®åˆ¤æ–­ã‚’è¨˜éŒ²ã™ã‚‹é–¢æ•°"""
    memory.save_context({"input": input_text}, {"output": result})
    vectorstore.persist()  # ğŸ§  ä¿å­˜å‡¦ç†ã‚’è¿½åŠ ï¼
    print("âœ… è¨˜éŒ²å®Œäº†ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æ¸ˆã¿ï¼‰")

def search_similar(input_text: str):
    """ä¼¼ãŸåˆ¤æ–­ã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°"""
    results = memory.load_memory_variables({"input": input_text})
    return results
